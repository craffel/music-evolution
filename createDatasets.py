# -*- coding: utf-8 -*-
# <nbformat>3.0</nbformat>

# <codecell>

import test
import numpy as np
import msd
import os
import tables
import scipy.stats.mstats
import csv
import collections
import random
import paths

# <codecell>

def makeFileListCSV( path, extension, csvFilename ):
    """ 
    Generates a CSV with rows filename,pathToFile for each file with the given extension in path
    
    Inputs:
        path - The path to look for files in
        extension - The extension to look for
        csvFilename - the file to write
    """
    # Open the CSV file for writing
    csvFile = open( csvFilename, 'wb' )
    csvWriter = csv.writer( csvFile )
    # Find all of the files in the given path
    for root, subdirectories, files in os.walk( path ):
        for file in files:
            # Only get files of the given type
            if os.path.splitext(file)[1] == extension:
                # Write out row
                csvWriter.writerow( [os.path.splitext(file)[0], os.path.join(root, file)] )

# <codecell>

def getFileListFromCSV( csvFilename ):
    """ 
    Generates a dict where fileList[filenameWithoutExtension] = pathToThatFile from a .csv filelist generated by makeFileListCSV
    
    Inputs:
        csvFileName - Name of the file tor ead from
    Outputs:
        fileList - dict as described above
    """
    # Open the supplied file
    csvFile = open( csvFilename, mode='r' )
    reader = csv.reader( csvFile )
    # Return dict where key is the first entry of each row, value is the second
    return dict((rows[0],rows[1]) for rows in reader)

# <codecell>

def getYearToFileMapping( tracksPerYearFile ):
    """ 
    Generates a dict where fileList[year] = [list of files for this year] from the "tracks_per_year.txt" file
    
    Inputs:
        tracksPerYearFile - path to "tracks_per_year.txt"
    Outputs:
        fileList - dict as described above
    """
    # Open the supplied file
    csvFile = open( tracksPerYearFile, mode='r' )
    reader = csv.reader( csvFile )
    # Return dict where key is the first entry of each row, value is the second
    fileList = collections.defaultdict( list )
    for row in reader:
        splitRow = row[0].split("<SEP>")
        fileList[int(splitRow[0])].append( splitRow[1] )
    return fileList

# <codecell>

def getFilenamesForYearRange( fileList, yearToFilename, yearRange ):
    """ 
    Generates a list of file paths which correspond to a given year range
    
    Inputs:
        fileList - dict from getFileListFromCSV giving the path for each filename
        yearToFilename - dict from getYearToFileMapping giving the filenames for a year
        yearRange - array of years to get filenames from
    Outputs:
        fileList - a list of paths for this year range
    """
    # We'll add file paths to this for each year
    fileListForYearRange = []
    for year in yearRange:
        # Get filenames for this year
        filesForThisYear = yearToFilename[year]
        # Store each filename in the list
        for filename in filesForThisYear:
            fileListForYearRange.append( fileList[filename] )
    return fileListForYearRange

# <markdowncell>

# "For each year, we sample one million beat-consecutive codewords, considering entire tracks and using a window length of 5 years"

# <codecell>

def getRandomSubsample( fileList, year, **kwargs ):
    """
    Given a year, returns nVectors of pitch/timbre/loudness descriptions from tracks in a 5-year window centered around that year.

    Input:
        fileList - list of hdf5 files to retrieve information from
        year - Year to sample from
        nVectors - the number of vectors to grab (default 1,000,000)
        seed - integer to seed the random number generator (default 0)
    Output: 
        pitchVectors - Matrix of random pitch vectors grabbed, size = (maxYear-minYear) x nVectors x 12
        timbreVectors - Same for timbre...
        loudnessValues - Vectors of random loudness values grabbed, size = (maxYear-minYear) x nVectors
        trackIndices - eg pitchVectors[year, trackIndices[year, n]:trackIndices[year, n+1]] are the pitch vectors for track n for some year
    """
    # Get keyword arguments
    nVectors = kwargs.get( 'nVectors', 1000000 )
    seed = kwargs.get( 'seed', 0 )
    np.random.seed( seed )
    # Create a copy of the file list because we'll be deleting elements from it
    fileList = list( fileList )
    # Matrix allocation
    pitchVectors = np.zeros( (nVectors, 12) )
    timbreVectors = np.zeros( (nVectors, 11) )
    loudnessValues = np.zeros( nVectors )
    # Will trim this later...
    trackIndices = np.zeros( nVectors )
    tracksWritten = 0
    # Where in the matrix are we writing values? Start from zero.
    index = 0
    # Keep going until the file list is empty (there will be other stopping conditions)
    while len( fileList ) > 0:
        # Get a random file from the remaining list
        randomIndex = np.random.randint( 0, len( fileList ))
        filename = fileList[randomIndex]
        # Remove so we don't retrieve this entry again
        del fileList[randomIndex]
        # Get hdf5 object
        h5 = tables.openFile( filename, mode='r' )
        # Get this entry's year
        trackYear = msd.hdf5_getters.get_year( h5 )
        # If the year isn't within two years, skip
        if trackYear > year + 2 or trackYear < year - 2:
            h5.close()
            continue
        # Get the data we care about
        trackPitchVectors = msd.beat_aligned_feats.get_btchromas( h5 )
        # Sometimes get_btchromas returns None
        if trackPitchVectors is None:
            continue
        else:
            trackPitchVectors = trackPitchVectors.T
        # We only want the last 11 timbre values but we don't know if get_bttimbre will fail so store in a temp variable first
        tempTimbreVectors = msd.beat_aligned_feats.get_bttimbre( h5 )
        if tempTimbreVectors is None:
            continue
        else:
            trackTimbreVectors = (tempTimbreVectors.T)[:, 1:]
        # They use the 0th timbre value as the loudness
        trackLoudnessValues = (tempTimbreVectors.T)[:, 0]
        h5.close()
        # Store values
        nBeats = trackPitchVectors.shape[0]
        storeRange = np.r_[index:np.clip( index+nBeats, 0, nVectors)]
        valuesToStore = pitchVectors[storeRange].shape[0]
        pitchVectors[storeRange] = trackPitchVectors[:valuesToStore]
        timbreVectors[storeRange] = trackTimbreVectors[:valuesToStore]
        loudnessValues[storeRange] = trackLoudnessValues[:valuesToStore]
        trackIndices[tracksWritten] = index
        tracksWritten += 1
        index += nBeats
        # Have we gotten enough vectors for all years yet?
        if (index >= nVectors):
            break
    # Trim track index list
    trackIndices = trackIndices[:tracksWritten]
    # Did we end without getting enough vectors?
    if len( fileList ) == 0:
        print "WARNING -- {0} vectors requested, only {1} found for year {2}".format( nVectors, index, year )
        pitchVectors = pitchVectors[:index]
        timbreVectors = timbreVectors[:index]
        loudnessValues = loudnessValues[:index]
    return pitchVectors, timbreVectors, loudnessValues, trackIndices

# <markdowncell>

# "We use a single threshold set to 0.5 and map the original pitch vector values to 0 or 1"
# 
# "...we make use of a ternary, equal-frequency encoding"
# 
# "To study transitions between loudness values and build a complex network we use an unsupervised equal-width discretization into 300 equal steps."

# <codecell>

def quantize( matrix, quantiles ):
    """
    Quantizes to values using thresholds in quantiles

    Input:
        matrix - input matrix to quantize
        quantiles - list of quantiles
    Output: 
        quantizedMatrix - ...
    """
    # Make sure quantiles is a numpy arra
    quantiles = np.array( quantiles )
    # Create output matrix
    quantizedMatrix = np.zeros( matrix.shape, dtype=np.int )
    # Convert to int values...
    for quantile in quantiles:
        quantizedMatrix += matrix > quantile
    # Make matrix binary if ony one quantile was given
    if quantiles.shape == (1,):
        quantizedMatrix = np.array( quantizedMatrix, dtype=np.bool )
    return quantizedMatrix

# <markdowncell>

# "Before discretization, pitch descriptions of each track are automatically transposed to an equivalent main tonality, such that all pitch codewords are considered within the same tonal context or key. For this process we employ a circular shift strategy, correlating (shifted) per-track averages to cognitively-inspired tonal pro
# 
# 
# 
# files."

# <codecell>

def shiftPitchVectors( pitchVectors, trackIndices ):
    """
    Circularly shift pitch vectors to a common key.

    Input:
        pitchVectors - Matrix of pitch vectors
        trackIndices - indices of the starts of tracks in pitchVectors
    Output: 
        shiftedPitchVectors - Matrix of shifted
    """
    # These values from http://musicweb.ucsd.edu/~sdubnov/CATbox/miditoolbox/refstat.m and elsewhere
    reference = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88])
    shiftedPitchVectors = np.zeros( pitchVectors.shape )
    # Cycle through track start and end times
    for trackStart, trackEnd in zip( trackIndices, np.append( trackIndices[1:], np.array( [pitchVectors.shape[0]] ) ) ):
        # Grab pitch vectors for this track
        trackPitchVectors = pitchVectors[trackStart:trackEnd]
        # Compute mean of pitch vectors for this track
        meanPitchVector = np.mean( trackPitchVectors, axis=0 )
        # Compute dot products for all shifts
        dotProducts = np.zeros( 12 )
        for shift in xrange( 12 ):
            dotProducts[shift] = np.dot( np.roll( meanPitchVector, shift ), reference )
        # Get best shift and store shifted vector
        bestShift = np.argmax( dotProducts )
        shiftedPitchVectors[trackStart:trackEnd] = np.roll( trackPitchVectors, bestShift, axis=1 )
    return shiftedPitchVectors

# <markdowncell>

# "We randomly chose one million timbre vectors from the dataset such that a maximum of 8,000 vectors corresponded to the same year."

# <codecell>

def getTimbreSample( fullFileList, yearToFileMapping, **kwargs ):
    """
    Get nVectors beat-based timbre vectors such that at most maxVectorsPerYear come from each year

    Input:
        fullFileList - a list of locations of all files to read vectors from
        yearToFileMapping - dict such that yearToFileMapping[year] = [list of filenames for this year]
        nVectors - number of vectors to retrieve (default 1,000,000)
        maxVectorsPerYear - maximum number of vectors to grab for each year (default 8,000)
    Output: 
        timbreSample - nVectors timbre vectors sampled as described above
    """
    # Get keyword arguments
    nVectors = kwargs.get( 'nVectors', 1000000 )
    maxVectorsPerYear = kwargs.get( 'maxVectorsPerYear', 8000 )
    # We'll be deleting from these, so copy them
    yearToFileMapping = dict( yearToFileMapping )
    fullFileList = dict( fullFileList )
    # Keep track of the number of vectors grabbed per year
    vectorsPerYear = {}
    for year in yearToFileMapping:
        vectorsPerYear[year] = 0
    timbreSample = np.zeros( (nVectors, 11) )
    # Keep track of the number of vectors grabbed total
    index = 0
    while index < nVectors:
        # Have we run out of tracks to read?
        if len( yearToFileMapping ) == 0:
            print "Ran out of tracks!  Only read {0} vectors.".format( index )
            timbreSample = timbreSample[:index]
            break
        # Generate a random year from the keys of yearToFileMapping
        randomYear = random.choice( list( yearToFileMapping.keys() ) )
        # Get the file list for this year
        fileList = yearToFileMapping[randomYear]
        # Get a random file from fileList
        if len(fileList) > 1:
            randomIndex = np.random.randint( 0, len(fileList) - 1 )
            filename = fullFileList[fileList[randomIndex]]
            del fileList[randomIndex]
        else:
            filename = fullFileList[fileList[0]]
            del yearToFileMapping[randomYear]
        # Get beat-based timbre vectors for this file
        h5 = tables.openFile( filename, mode='r' )
        # Get this entry's year
        trackYear = msd.hdf5_getters.get_year( h5 )
        # If the year is wrong, skip
        if trackYear != randomYear:
            h5.close()
            continue
        # We only want the last 11 timbre values but we don't know if get_bttimbre will return None
        trackTimbreVectors = msd.beat_aligned_feats.get_bttimbre( h5 )
        h5.close()
        if trackTimbreVectors is None:
            continue
        else:
            trackTimbreVectors = (trackTimbreVectors.T)[:, 1:]
        # Check to see if we will have found maxVectorsPerYear vectors, and truncate the vectors and delete this year if so
        if vectorsPerYear[randomYear] + trackTimbreVectors.shape[0] > maxVectorsPerYear:
            trackTimbreVectors = trackTimbreVectors[:maxVectorsPerYear - vectorsPerYear[randomYear]]
            if randomYear in yearToFileMapping:
                del yearToFileMapping[randomYear]
        # Store the vectors for this file
        storeRange = np.r_[index:np.clip( index + trackTimbreVectors.shape[0], 0, nVectors)]
        valuesToStore = timbreSample[storeRange].shape[0]
        timbreSample[storeRange] = trackTimbreVectors[:valuesToStore]
        index += trackTimbreVectors.shape[0]
        vectorsPerYear[randomYear] += trackTimbreVectors.shape[0]
    print vectorsPerYear
    return timbreSample

# <markdowncell>

# "Thresholds are set to the 33 and 66% quantiles of a representative sample of beat-based timbre description values."

# <codecell>

def getQuantiles( matrix, quantiles ):
    """
    Given a matrix, compute quantiles for each column

    Input:
        matrix - matrix nVectors x nVariables of values
        quantiles - the quantiles to compute
    Output: 
        quantilesPerColumn - array of size nQuantiles x nVariables indicating the quantile for each column
    """
    # Get the number of columns (variables)
    nVariables = matrix.shape[1]
    quantilesPerColumn = np.zeros( (len( quantiles ), nVariables) )
    for n in xrange( nVariables ):
        quantilesPerColumn[:, n] = scipy.stats.mstats.mquantiles( matrix[:, n], quantiles )
    return quantilesPerColumn

# <markdowncell>

# "Loudness values are originally provided in decibels (dB), and limited within a range from 0 to 60. Nonetheless, in order to conform to the standard signal processing criterion [19], we subtract the loudness reference of 60 dB used in the million song dataset from them."

# <codecell>

def timbreZeroToDb( loudnessValues ):
    """
    Given a timbre coefficient zero, convert to dB in the range [-60, 0]

    Input:
        loudnessValues - timbre coefficient 0
    Output: 
        loudnessValues - dB values
    """
    return np.clip( loudnessValues, 0, 60 ) - 60

# <codecell>

# Create the data subset - this also only needs to be run once!!!!
if __name__ == "__main__":
    # Generate the file list - this only needs to be run once.
    if not os.path.isfile( paths.fileListName ):
        makeFileListCSV( paths.msdPath, '.h5', paths.fileListName )
    fullFileList = getFileListFromCSV( paths.fileListName )
    yearToFileMapping = getYearToFileMapping( paths.yearToFileMappingName )
    # Generate the timbre sample - this also only needs to be run once
    if not os.path.isfile( os.path.join( paths.subsamplePath, 'timbreSample.npy' ) ):
        timbreSample = getTimbreSample( fullFileList, yearToFileMapping )
        np.save( os.path.join( paths.subsamplePath, 'timbreSample.npy' ), timbreSample )
    timbreSample = np.load( os.path.join( paths.subsamplePath, 'timbreSample.npy' ) )
    # They perform the random sampling 10 times!
    for seed in np.arange( 10 ):
        for year in np.arange( 1955, 2009 ):
            fileList = getFilenamesForYearRange( fullFileList, yearToFileMapping, np.arange(year - 2, year + 3) )
            pitchVectors, timbreVectors, loudnessValues, trackIndices = getRandomSubsample( fileList, year, seed=seed )
            # Shift and quantize (simple binary threshold) the pitch vectors
            shiftedPitchVectors = shiftPitchVectors( pitchVectors, trackIndices )
            quantizedShiftedPitchVectors = quantize( shiftedPitchVectors, [.5] )
            np.save( os.path.join( paths.subsamplePath, 'msd-pitches-' + str( year ) + '-' + str( seed ) + '.npy'), quantizedShiftedPitchVectors )
            # Quantize to quantiles
            timbreQuantiles = getQuantiles( timbreSample, [.33, .66] )
            quantizedTimbreVectors = quantize( timbreVectors, timbreQuantiles )
            np.save( os.path.join( paths.subsamplePath, 'msd-timbre-' + str( year ) + '-' + str( seed ) + '.npy', quantizedTimbreVectors )
            # Convert timbre coefficient zero to dB values in [0, 60] and quantize them
            loudnessValues = timbreZeroToDb( loudnessValues )
            quantizedLoudnessValues = quantize( loudnessValues, np.linspace( -59.8, -.2, 299 ) )
            np.save( os.path.join( paths.subsamplePath, 'msd-loudness-' + str( year ) + '-' + str( seed ) + '.npy', quantizedLoudnessValues )
            # Also save the track indices
            np.save( os.path.join( paths.subsamplePath, 'msd-trackIndices-' + str( year ) + '-' + str( seed ) + '.npy', trackIndices )

