{
 "metadata": {
  "name": "createDatasets"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import msd\n",
      "import os\n",
      "import tables"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "You don't have the 'pg' module, can't use musicbrainz server\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getFiles( path, extension ):\n",
      "    \"\"\" \n",
      "    Get files of a certain type in a directory, recursively\n",
      "    \n",
      "    Inputs:\n",
      "        path - The path to look for files in\n",
      "        extension - The extension to look for\n",
      "    Outputs:\n",
      "        fileList - a list of all files with this extension, including their paths relative to path\n",
      "    \"\"\"\n",
      "    fileList = []\n",
      "    for root, subdirectories, files in os.walk( path ):\n",
      "        for file in files:\n",
      "            # Only get files of the given type\n",
      "            if os.path.splitext(file)[1] == extension:\n",
      "                fileList.append(os.path.join(root, file))\n",
      "    return fileList\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"For each year, we sample one million beat-consecutive codewords, considering entire tracks and using a window length of 5 years\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getRandomSubsample( fileList, **kwargs ):\n",
      "    \"\"\"\n",
      "    Given a year, returns nVectors of pitch/timbre/loudness descriptions from tracks in a 5-year window centered around that year.\n",
      "\n",
      "    Input:\n",
      "        fileList - list of hdf5 files to retrieve information from\n",
      "        minYear - First year to sample from (default 1955)\n",
      "        maxYear - Last year to sample from (default 2008)\n",
      "        nVectors - the number of vectors to grab (default 1,000,000)\n",
      "        seed - integer to seed the random number generator (default 0)\n",
      "    Output: \n",
      "        pitchVectors - Matrix of random pitch vectors grabbed, size = (maxYear-minYear) x nVectors x 12\n",
      "        timbreVectors - Same for timbre...\n",
      "        loudnessValues - Vectors of random loudness values grabbed, size = (maxYear-minYear) x nVectors\n",
      "    \"\"\"\n",
      "    # Get keyword arguments\n",
      "    minYear = kwargs.get( 'minYear', 1955 )\n",
      "    maxYear = kwargs.get( 'maxYear', 2008 )\n",
      "    nVectors = kwargs.get( 'nVectors', 1000000 )\n",
      "    seed = kwargs.get( 'seed', 0 )\n",
      "    np.random.seed( seed )\n",
      "    # Create a copy of the file list because we'll be deleting elements from it\n",
      "    fileList = list( fileList )\n",
      "    # Matrix allocation\n",
      "    pitchVectors = np.zeros( (maxYear - minYear + 1, nVectors, 12) )\n",
      "    timbreVectors = np.zeros( (maxYear - minYear + 1, nVectors, 12) )\n",
      "    loudnessValues = np.zeros( (maxYear - minYear + 1, nVectors) )\n",
      "    # Where in the matrix are we writing values? Start from zero.\n",
      "    perYearIndex = np.zeros( (maxYear - minYear + 1), dtype=np.int )\n",
      "    # Keep going until the file list is empty (there will be other stopping conditions)\n",
      "    while len( fileList ) > 0:\n",
      "        # Get a random file from the remaining list\n",
      "        randomIndex = np.random.randint( 0, len( fileList ))\n",
      "        filename = fileList[randomIndex]\n",
      "        # Remove so we don't retrieve this entry again\n",
      "        del fileList[randomIndex]\n",
      "        # Get hdf5 object\n",
      "        h5 = tables.openFile( filename, mode='r' )\n",
      "        # Get this entry's year\n",
      "        year = msd.hdf5_getters.get_year( h5 )\n",
      "        # Get the data we care about\n",
      "        trackPitchVectors = msd.hdf5_getters.get_segments_pitches( h5 )\n",
      "        trackTimbreVectors = msd.hdf5_getters.get_segments_timbre( h5 )\n",
      "        trackLoudnessValues = msd.hdf5_getters.get_segments_loudness_max( h5 )\n",
      "        h5.close()\n",
      "        # If no year is listed or its out of the range we care about, skip\n",
      "        if year == 0 or year + 2 < minYear or year - 2 > maxYear:\n",
      "            continue\n",
      "        # Cycle through years, starting from two years prior to two years after\n",
      "        for yearIndex in np.arange( np.clip( year - 2, minYear, np.inf ), np.clip( (year + 2), 0, maxYear ) + 1 ) - minYear:\n",
      "            # Have we already gotten enough values for this year?\n",
      "            if perYearIndex[yearIndex] >= nVectors:\n",
      "                continue\n",
      "            # Store values\n",
      "            # I think I am supposed to do the circular shift here...\n",
      "            nSegments = trackPitchVectors.shape[0]\n",
      "            storeRange = np.r_[perYearIndex[yearIndex]:np.clip( perYearIndex[yearIndex]+nSegments, 0, nVectors)]\n",
      "            valuesToStore = pitchVectors[yearIndex, storeRange].shape[0]\n",
      "            pitchVectors[yearIndex, storeRange] = trackPitchVectors[:valuesToStore]\n",
      "            timbreVectors[yearIndex, storeRange] = trackTimbreVectors[:valuesToStore]\n",
      "            loudnessValues[yearIndex, storeRange] = trackLoudnessValues[:valuesToStore]\n",
      "            perYearIndex[yearIndex] += nSegments\n",
      "        # Have we gotten enough vectors for all years yet?\n",
      "        if (perYearIndex >= nVectors).all():\n",
      "            break\n",
      "    # Did we end without getting enough vectors?\n",
      "    if len( fileList ) == 0:\n",
      "        print \"WARNING -- not enough tracks were found for all years.\"\n",
      "    return pitchVectors, timbreVectors, loudnessValues"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"We use a single threshold set to 0.5 and map the original pitch vector values to 0 or 1\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def quantizePitchVectors( pitchVectors ):\n",
      "    \"\"\"\n",
      "    Quantizes pitch vectors to binary values using a threshold of .5.\n",
      "\n",
      "    Input:\n",
      "        pitchVectors - Matrix of pitch vectors\n",
      "    Output: \n",
      "        quantizedPitchVectors - Matrix of quantized pitch vectors\n",
      "    \"\"\"\n",
      "    return pitchVectors > 0.5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the data subset\n",
      "if __name__ == \"__main__\":\n",
      "    fileList = getFiles( \"Data/MillionSongSubset/\", \".h5\" )\n",
      "    # Seems like there are enough in the MSS to support 8000 vectors per year.\n",
      "    pitchVectors, timbreVectors, loudnessValues = getRandomSubsample( fileList, nVectors=8000 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}